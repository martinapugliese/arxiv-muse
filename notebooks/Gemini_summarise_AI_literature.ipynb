{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "provenance": [],
      "authorship_tag": "ABX9TyMBC79z9yr1gqlcWtJCPnMe",
      "include_colab_link": true
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "language_info": {
      "name": "python"
    }
  },
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "view-in-github",
        "colab_type": "text"
      },
      "source": [
        "<a href=\"https://colab.research.google.com/github/martinapugliese/summarise-sci-literature/blob/main/notebooks/Gemini_summarise_AI_literature.ipynb\" target=\"_parent\"><img src=\"https://colab.research.google.com/assets/colab-badge.svg\" alt=\"Open In Colab\"/></a>"
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "# this is to get time execution on each cell\n",
        "!pip install ipython-autotime\n",
        "\n",
        "%load_ext autotime"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "6TV5IJ7fZ3uL",
        "outputId": "eb6e7fae-0a80-48ad-b13a-d73a6c40b65d"
      },
      "execution_count": 1,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Requirement already satisfied: ipython-autotime in /usr/local/lib/python3.11/dist-packages (0.3.2)\n",
            "Requirement already satisfied: ipython in /usr/local/lib/python3.11/dist-packages (from ipython-autotime) (7.34.0)\n",
            "Requirement already satisfied: setuptools>=18.5 in /usr/local/lib/python3.11/dist-packages (from ipython->ipython-autotime) (75.1.0)\n",
            "Requirement already satisfied: jedi>=0.16 in /usr/local/lib/python3.11/dist-packages (from ipython->ipython-autotime) (0.19.2)\n",
            "Requirement already satisfied: decorator in /usr/local/lib/python3.11/dist-packages (from ipython->ipython-autotime) (4.4.2)\n",
            "Requirement already satisfied: pickleshare in /usr/local/lib/python3.11/dist-packages (from ipython->ipython-autotime) (0.7.5)\n",
            "Requirement already satisfied: traitlets>=4.2 in /usr/local/lib/python3.11/dist-packages (from ipython->ipython-autotime) (5.7.1)\n",
            "Requirement already satisfied: prompt-toolkit!=3.0.0,!=3.0.1,<3.1.0,>=2.0.0 in /usr/local/lib/python3.11/dist-packages (from ipython->ipython-autotime) (3.0.50)\n",
            "Requirement already satisfied: pygments in /usr/local/lib/python3.11/dist-packages (from ipython->ipython-autotime) (2.18.0)\n",
            "Requirement already satisfied: backcall in /usr/local/lib/python3.11/dist-packages (from ipython->ipython-autotime) (0.2.0)\n",
            "Requirement already satisfied: matplotlib-inline in /usr/local/lib/python3.11/dist-packages (from ipython->ipython-autotime) (0.1.7)\n",
            "Requirement already satisfied: pexpect>4.3 in /usr/local/lib/python3.11/dist-packages (from ipython->ipython-autotime) (4.9.0)\n",
            "Requirement already satisfied: parso<0.9.0,>=0.8.4 in /usr/local/lib/python3.11/dist-packages (from jedi>=0.16->ipython->ipython-autotime) (0.8.4)\n",
            "Requirement already satisfied: ptyprocess>=0.5 in /usr/local/lib/python3.11/dist-packages (from pexpect>4.3->ipython->ipython-autotime) (0.7.0)\n",
            "Requirement already satisfied: wcwidth in /usr/local/lib/python3.11/dist-packages (from prompt-toolkit!=3.0.0,!=3.0.1,<3.1.0,>=2.0.0->ipython->ipython-autotime) (0.2.13)\n",
            "time: 353 µs (started: 2025-02-22 16:12:04 +00:00)\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "from google.colab import userdata, drive\n",
        "\n",
        "from pydantic import BaseModel, Field\n",
        "from inspect import cleandoc\n",
        "\n",
        "from google import genai\n",
        "from google.genai import Client, types\n",
        "\n",
        "import requests\n",
        "import urllib.request as urllib_req\n",
        "from bs4 import BeautifulSoup\n",
        "\n",
        "from datetime import date, datetime\n",
        "\n",
        "import re\n",
        "\n",
        "import os\n",
        "import shutil\n",
        "import json\n",
        "\n",
        "import numpy as np"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "MjqfEPBGNaoE",
        "outputId": "04947ff7-461f-40a5-c8d2-fdb50982539a"
      },
      "execution_count": 2,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "/usr/local/lib/python3.11/dist-packages/pydantic/_internal/_generate_schema.py:502: UserWarning: <built-in function any> is not a Python type (it may be an instance of an object), Pydantic will allow any object with no validation since we cannot even enforce that the input is an instance of the given type. To get rid of this error wrap the type with `pydantic.SkipValidation`.\n",
            "  warn(\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "time: 3.32 s (started: 2025-02-22 16:12:05 +00:00)\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "## Configs"
      ],
      "metadata": {
        "id": "PYFL0-uMJqOY"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "client = genai.Client(api_key=userdata.get('GEMINI_API_KEY'))"
      ],
      "metadata": {
        "id": "rsM-SO6JNqud",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "041cbf1f-9d00-48af-a439-672c45c5af53"
      },
      "execution_count": 3,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "time: 846 ms (started: 2025-02-22 16:12:10 +00:00)\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "# configure which Gemini to run\n",
        "model_id = \"gemini-2.0-flash-lite-preview-02-05\"\n",
        "model_id = \"gemini-2.0-flash\""
      ],
      "metadata": {
        "id": "HFu1maz4PK_Y",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "c0eb63db-c598-4d31-cd10-0ea02c2f6d2c"
      },
      "execution_count": 4,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "time: 517 µs (started: 2025-02-22 16:12:12 +00:00)\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "## Scrape ArXiv page for latest day's AI papers\n",
        "\n",
        "Get the paper links and IDs. Use the most recent days of publications available."
      ],
      "metadata": {
        "id": "AwAzV6WeJc-4"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "webpage = \"https://arxiv.org/list/cs.AI/recent?skip=0&show=2000\"  # this is the URL for all, so no need to paginate\n",
        "\n",
        "r = requests.get(webpage)\n",
        "r.status_code  # you want a 200 here"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "collapsed": true,
        "id": "aUUr_6uZTz9A",
        "outputId": "6701d3d4-2bb6-4cd4-c411-83ee86f1bbf0"
      },
      "execution_count": 5,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "200"
            ]
          },
          "metadata": {},
          "execution_count": 5
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "time: 195 ms (started: 2025-02-22 16:12:15 +00:00)\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "# initialise the parser\n",
        "soup = BeautifulSoup(r.content, \"html.parser\")"
      ],
      "metadata": {
        "id": "qM02iz80NXLZ",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "594d5323-e3e2-4395-8a44-39ec032e3aea"
      },
      "execution_count": 6,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "time: 3.96 s (started: 2025-02-22 16:12:17 +00:00)\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "# pick the phrasing of the most recent day\n",
        "latest_day_str = soup.find_all(\"h3\")[0].text\n",
        "\n",
        "# match what's this latest day\n",
        "day = latest_day_str.split('(')[0]\n",
        "\n",
        "# and the total number of entries for that day\n",
        "match = re.search(r'of \\d+ entries', latest_day_str)\n",
        "if match:\n",
        "    n_entries = int(match.group().split(' ')[1])\n",
        "    print(day, ' - ', n_entries, 'papers')\n",
        "else:\n",
        "    print(\"Failed to isolate latest day's info\")"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "xhte_voMMnxT",
        "outputId": "f1d6f491-22d2-4d63-d90e-4717e4824f36"
      },
      "execution_count": 7,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Fri, 21 Feb 2025   -  154 papers\n",
            "time: 30.7 ms (started: 2025-02-22 16:12:21 +00:00)\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "# now find the URLs to these papers for the latest day only (up to n_entries as per above)\n",
        "paper_links = soup.find_all(\"a\", {\"title\": \"Download PDF\"})[:n_entries]\n",
        "\n",
        "# Extract the paper IDs and links\n",
        "paper_ids, paper_urls = [], []\n",
        "for link in paper_links:\n",
        "    paper_url = \"https://arxiv.org\" + link[\"href\"]\n",
        "    paper_id = link[\"href\"].split(\"/\")[-1].split(\"v\")[0]  # Extract the ID\n",
        "\n",
        "    paper_ids.append(paper_id)\n",
        "    paper_urls.append(paper_url)"
      ],
      "metadata": {
        "id": "Fp1ngoJ-YYbJ",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "c75629df-1b28-4761-b448-0715f7309d40"
      },
      "execution_count": 8,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "time: 70.6 ms (started: 2025-02-22 16:12:24 +00:00)\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "# separately, find all titles (this is due to how the DOM is structured)\n",
        "# they'll appear in the same order so order counts\n",
        "paper_title_divs = soup.find_all(\"div\", {\"class\": \"list-title mathjax\"})[:n_entries]\n",
        "\n",
        "paper_titles = []\n",
        "for title_div in paper_title_divs:\n",
        "    paper_titles.append(title_div.contents[1].split('\\n')[1].lstrip())"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "collapsed": true,
        "id": "A7GBjw9ECsoq",
        "outputId": "ca601992-0f9b-40fb-ce91-94a1a2e45a26"
      },
      "execution_count": 9,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "time: 75.6 ms (started: 2025-02-22 16:12:27 +00:00)\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "len(paper_urls), len(paper_ids), len(paper_links), len(paper_titles)"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "Zi8o9t3lKwml",
        "outputId": "ccfad0b5-87eb-4ba3-fcd9-4a735a254e3a"
      },
      "execution_count": 31,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "(154, 154, 154, 154)"
            ]
          },
          "metadata": {},
          "execution_count": 31
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "time: 3.4 ms (started: 2025-02-22 16:35:24 +00:00)\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "# create json linking ID and URL\n",
        "paper_metadata = {paper_ids[i]: {'url': paper_urls[i]} for i in range(len(paper_ids))}\n",
        "json.dump(paper_metadata, open('paper_metadata.json', 'w'))"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "LpzPSOkY_0GH",
        "outputId": "e62f2c7d-1ea3-4aa1-c1f2-0330508dc859"
      },
      "execution_count": 32,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "time: 3.83 ms (started: 2025-02-22 16:35:47 +00:00)\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "## Download all papers locally"
      ],
      "metadata": {
        "id": "NHv-Foa5Ko0V"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "os.mkdir('pdfs')\n",
        "\n",
        "i = 0\n",
        "for id_, url_ in zip(paper_ids, paper_urls):\n",
        "    _ = urllib_req.urlretrieve(url_, f\"pdfs/{id_}.pdf\")\n",
        "\n",
        "    i += 1\n",
        "    if i % 10 == 0:\n",
        "        print(f\"Downloaded {i} papers\")"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "GsZItTXDZEKu",
        "outputId": "978b74f2-dc51-47b3-c549-cb9e1f93e6a0"
      },
      "execution_count": 18,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Downloaded 10 papers\n",
            "Downloaded 20 papers\n",
            "Downloaded 30 papers\n",
            "Downloaded 40 papers\n",
            "Downloaded 50 papers\n",
            "Downloaded 60 papers\n",
            "Downloaded 70 papers\n",
            "Downloaded 80 papers\n",
            "Downloaded 90 papers\n",
            "Downloaded 100 papers\n",
            "Downloaded 110 papers\n",
            "Downloaded 120 papers\n",
            "Downloaded 130 papers\n",
            "Downloaded 140 papers\n",
            "Downloaded 150 papers\n",
            "time: 21.9 s (started: 2025-02-22 16:13:39 +00:00)\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "len(os.listdir('pdfs'))  # just to check count"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "kviwBfwughb1",
        "outputId": "908c9a3a-73c1-47f7-e3ab-4a46cbad20ac"
      },
      "execution_count": 19,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "154"
            ]
          },
          "metadata": {},
          "execution_count": 19
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "time: 3.99 ms (started: 2025-02-22 16:14:01 +00:00)\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "## Make Gemini summarise each paper"
      ],
      "metadata": {
        "id": "9TD9hhq-aoM1"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "# define a Pydantic model for the response\n",
        "class PaperInfo(BaseModel):\n",
        "    title: str = Field(description=\"Title of the paper\")\n",
        "    summary: str = Field(description=\"Summary of the paper, in 3 lines\")\n",
        "    examples: list[str] = Field(description=\"Relevant examples aiding comprehension, taken from the paper, if there are.\")\n",
        "    category: str = Field(description='Category of the paper')"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "QsDdboVHMDTt",
        "outputId": "78223299-6c9a-4595-a74a-cb235dd12d82"
      },
      "execution_count": 21,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "time: 6.62 ms (started: 2025-02-22 16:14:48 +00:00)\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "# prompt\n",
        "sys_instruct = cleandoc(\n",
        "    \"\"\"\n",
        "    You are an experienced reader of academic literature and\n",
        "    an expert in distilling important findings in a way that is understandable and clear.\n",
        "    \"\"\")\n",
        "\n",
        "prompt = cleandoc(\n",
        "    \"\"\"This is a paper on AI.\n",
        "    Parse its title, summarise its results, extract examples and produce a category.\n",
        "    For the summary, be concise and avoid obscure jargon.\n",
        "    If there are valuable examples that aid understanding, report them in a nutshell.\n",
        "    For the category, think about what the results refer to, e.g. cognitive science, medicine, foundational AI etc.\n",
        "    \"\"\")"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "1Qu4OSOYgfC8",
        "outputId": "b0d3f8a8-a8eb-4bd5-fc38-f2a8dce7adb8"
      },
      "execution_count": 22,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "time: 656 µs (started: 2025-02-22 16:14:49 +00:00)\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "# create a dir for model responses (text)\n",
        "os.mkdir('responses')"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "J9--OwUrgu_m",
        "outputId": "ce5fe8a0-e5c1-476d-d437-dddd25ef7963"
      },
      "execution_count": 23,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "time: 607 µs (started: 2025-02-22 16:14:50 +00:00)\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "# create some dicts for data & metadata\n",
        "d_response, d_usage, d_latency = {}, {}, {}"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "d-6V3-QyiMdi",
        "outputId": "091496f5-cb34-4220-c36f-19337e2a6cc8"
      },
      "execution_count": 24,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "time: 501 µs (started: 2025-02-22 16:14:52 +00:00)\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "i = 0\n",
        "for filename in os.listdir('pdfs')[:]:\n",
        "\n",
        "    print(filename, i)\n",
        "\n",
        "    # this passes the file as is to Gemini, no need to read its text content first\n",
        "    file_ = client.files.upload(file=f'pdfs/{filename}')\n",
        "    id_ = filename.split('.pdf')[0]\n",
        "\n",
        "    start_time = datetime.now()\n",
        "    response = client.models.generate_content(\n",
        "        model=model_id,\n",
        "        config=types.GenerateContentConfig(\n",
        "            system_instruction=sys_instruct,\n",
        "            temperature=0,                       # use greeedy decoding\n",
        "            response_mime_type='application/json',\n",
        "            response_schema=PaperInfo\n",
        "            ),\n",
        "        contents=[prompt, file_])\n",
        "    end_time = datetime.now()\n",
        "\n",
        "    # This is to handle the safety filter if triggered\n",
        "    if response.prompt_feedback is not None:\n",
        "        print('This paper failed with feedback: ', response.prompt_feedback)\n",
        "    else:\n",
        "        d_response[id_] = json.loads(response.text)\n",
        "        d_usage[id_] = {\n",
        "            'prompt_token_count': response.usage_metadata.prompt_token_count,\n",
        "            'candidates_token_count': response.usage_metadata.candidates_token_count,\n",
        "            'cached_content_token_count': response.usage_metadata.cached_content_token_count}\n",
        "        d_latency[id_] = (end_time - start_time).total_seconds()\n",
        "\n",
        "        # create file of JSON response\n",
        "        json.dump(d_response[id_], open(f'responses/{id_}.json', 'w'))\n",
        "\n",
        "        # also dump usage and latency at each execution\n",
        "        json.dump(d_usage, open(f'usage.json', 'w'))\n",
        "        json.dump(d_latency, open(f'latency.json', 'w'))\n",
        "\n",
        "    i += 1"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "fJtFYt0tZHe9",
        "outputId": "75f1ec69-b6ef-4a38-b0aa-23f1d95e28bd"
      },
      "execution_count": 25,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "2502.14416.pdf 0\n",
            "2502.13969.pdf 1\n",
            "2502.14074.pdf 2\n",
            "2502.14000.pdf 3\n",
            "2502.14361.pdf 4\n",
            "2502.14581.pdf 5\n",
            "2502.14276.pdf 6\n",
            "2502.14043.pdf 7\n",
            "2502.14191.pdf 8\n",
            "2502.14499.pdf 9\n",
            "2502.14456.pdf 10\n",
            "2502.14645.pdf 11\n",
            "2502.14037.pdf 12\n",
            "2502.14838.pdf 13\n",
            "2502.14080.pdf 14\n",
            "2502.14563.pdf 15\n",
            "2502.14765.pdf 16\n",
            "2502.14558.pdf 17\n",
            "2502.14553.pdf 18\n",
            "2502.14807.pdf 19\n",
            "2502.14281.pdf 20\n",
            "2502.13994.pdf 21\n",
            "2502.14442.pdf 22\n",
            "2502.14334.pdf 23\n",
            "2502.14176.pdf 24\n",
            "2502.14457.pdf 25\n",
            "2502.14247.pdf 26\n",
            "2502.14777.pdf 27\n",
            "2502.14760.pdf 28\n",
            "2502.14070.pdf 29\n",
            "2502.14260.pdf 30\n",
            "2502.14293.pdf 31\n",
            "2502.14486.pdf 32\n",
            "2502.14525.pdf 33\n",
            "2502.14197.pdf 34\n",
            "2502.13983.pdf 35\n",
            "2502.14132.pdf 36\n",
            "2502.14572.pdf 37\n",
            "2502.14834.pdf 38\n",
            "2502.14619.pdf 39\n",
            "2502.13991.pdf 40\n",
            "2502.14698.pdf 41\n",
            "2502.14487.pdf 42\n",
            "2502.14380.pdf 43\n",
            "2502.14218.pdf 44\n",
            "2502.14113.pdf 45\n",
            "2502.14768.pdf 46\n",
            "2502.14001.pdf 47\n",
            "2502.14856.pdf 48\n",
            "2502.14318.pdf 49\n",
            "2502.14704.pdf 50\n",
            "2502.14458.pdf 51\n",
            "2502.14183.pdf 52\n",
            "2502.14753.pdf 53\n",
            "2502.14010.pdf 54\n",
            "2502.14272.pdf 55\n",
            "2502.14445.pdf 56\n",
            "2502.14724.pdf 57\n",
            "2502.14786.pdf 58\n",
            "2502.14202.pdf 59\n",
            "2502.14372.pdf 60\n",
            "2502.14529.pdf 61\n",
            "2502.14205.pdf 62\n",
            "2502.13979.pdf 63\n",
            "2502.14047.pdf 64\n",
            "2502.14681.pdf 65\n",
            "2502.14302.pdf 66\n",
            "2502.14727.pdf 67\n",
            "2502.14219.pdf 68\n",
            "2502.14815.pdf 69\n",
            "2502.13972.pdf 70\n",
            "2502.14546.pdf 71\n",
            "2502.14174.pdf 72\n",
            "2502.14045.pdf 73\n",
            "2502.14019.pdf 74\n",
            "2502.14627.pdf 75\n",
            "2502.14708.pdf 76\n",
            "2502.14504.pdf 77\n",
            "2502.14767.pdf 78\n",
            "2502.14802.pdf 79\n",
            "2502.14131.pdf 80\n",
            "2502.14023.pdf 81\n",
            "2502.14714.pdf 82\n",
            "2502.14837.pdf 83\n",
            "2502.14400.pdf 84\n",
            "2502.14676.pdf 85\n",
            "2502.14268.pdf 86\n",
            "2502.14620.pdf 87\n",
            "2502.14780.pdf 88\n",
            "2502.14297.pdf 89\n",
            "2502.14155.pdf 90\n",
            "2502.14862.pdf 91\n",
            "2502.14149.pdf 92\n",
            "2502.14204.pdf 93\n",
            "2502.14011.pdf 94\n",
            "2502.14301.pdf 95\n",
            "2502.14258.pdf 96\n",
            "2502.14114.pdf 97\n",
            "2502.14050.pdf 98\n",
            "2502.14799.pdf 99\n",
            "2502.14345.pdf 100\n",
            "2502.14382.pdf 101\n",
            "2502.14227.pdf 102\n",
            "2502.14469.pdf 103\n",
            "2502.14333.pdf 104\n",
            "2502.14462.pdf 105\n",
            "2502.14743.pdf 106\n",
            "2502.14215.pdf 107\n",
            "2502.14827.pdf 108\n",
            "2502.14788.pdf 109\n",
            "2502.14560.pdf 110\n",
            "2502.14160.pdf 111\n",
            "2502.14740.pdf 112\n",
            "2502.14121.pdf 113\n",
            "2502.14866.pdf 114\n",
            "2502.14365.pdf 115\n",
            "2502.14791.pdf 116\n",
            "2502.14013.pdf 117\n",
            "2502.14637.pdf 118\n",
            "2502.14864.pdf 119\n",
            "2502.14491.pdf 120\n",
            "2502.14671.pdf 121\n",
            "2502.14583.pdf 122\n",
            "2502.14068.pdf 123\n",
            "2502.14820.pdf 124\n",
            "2502.14102.pdf 125\n",
            "2502.14280.pdf 126\n",
            "2502.14003.pdf 127\n",
            "2502.14424.pdf 128\n",
            "2502.14200.pdf 129\n",
            "2502.14086.pdf 130\n",
            "2502.14706.pdf 131\n",
            "2502.14455.pdf 132\n",
            "2502.14254.pdf 133\n",
            "2502.14064.pdf 134\n",
            "2502.14785.pdf 135\n",
            "2502.14778.pdf 136\n",
            "2502.14143.pdf 137\n",
            "2502.14677.pdf 138\n",
            "2502.14759.pdf 139\n",
            "2502.14735.pdf 140\n",
            "2502.14831.pdf 141\n",
            "2502.14008.pdf 142\n",
            "2502.14255.pdf 143\n",
            "2502.14048.pdf 144\n",
            "2502.14273.pdf 145\n",
            "2502.14235.pdf 146\n",
            "2502.14222.pdf 147\n",
            "2502.14061.pdf 148\n",
            "2502.14316.pdf 149\n",
            "2502.14830.pdf 150\n",
            "2502.14366.pdf 151\n",
            "2502.13998.pdf 152\n",
            "2502.14264.pdf 153\n",
            "time: 18min 13s (started: 2025-02-22 16:14:53 +00:00)\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "## Run some stats"
      ],
      "metadata": {
        "id": "wtUaxd2Qjhup"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "# num papers summarised\n",
        "print('Summaries for ', day)\n",
        "print('Num papers published: ', n_entries)\n",
        "print('Num papers summarised: ', len(os.listdir('responses')))\n",
        "print('Median input/output tokens',\n",
        "      np.percentile([d_usage[k]['prompt_token_count'] for k in d_usage.keys()], 50),\n",
        "      np.percentile([d_usage[k]['candidates_token_count'] for k in d_usage.keys()], 50))\n",
        "print('Median/P90 latency per paper: ',\n",
        "      np.percentile([d_latency[k] for k in d_usage.keys()], 50),\n",
        "      np.percentile([d_latency[k] for k in d_usage.keys()], 90))"
      ],
      "metadata": {
        "id": "BZmHoOp4jjAn",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "7857857b-de5d-4bde-d6bf-90cec00a8e71"
      },
      "execution_count": 26,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Summaries for  Fri, 21 Feb 2025 \n",
            "Num papers published:  154\n",
            "Num papers summarised:  154\n",
            "Median input/output tokens 4271.0 198.5\n",
            "Median/P90 latency per paper:  5.4023425 9.537124200000003\n",
            "time: 10.3 ms (started: 2025-02-22 16:33:17 +00:00)\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "## Create HTML page with all summaries"
      ],
      "metadata": {
        "id": "OofFXJAPAFNv"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "# this part below was contributed by Gemini after a prompt!\n",
        "# prompt: Create HTML document listing all texts in folder response one after the other. Use the data in paper_metadata to create titles for each entry and an href for the link\n",
        "\n",
        "# Load paper metadata\n",
        "#paper_metadata = json.load(open('paper_metadata.json', 'r'))\n",
        "\n",
        "# Create HTML content\n",
        "html_content = \"\"\"<!DOCTYPE html>\n",
        "<html>\n",
        "<head>\n",
        "<title>Paper Summaries</title>\n",
        "</head>\n",
        "<body>\n",
        "\"\"\"\n",
        "\n",
        "for filename in os.listdir('responses'):\n",
        "    if '.ipynb' not in filename: # it may create this folder\n",
        "        paper_id = filename.split('.json')[0]\n",
        "        d_paper = json.load(open(os.path.join('responses', filename), 'r'))\n",
        "\n",
        "        if paper_id in paper_metadata:\n",
        "            title = d_paper['title']\n",
        "            url = paper_metadata[paper_id]['url']\n",
        "            summary = d_paper['summary']\n",
        "            examples = d_paper['examples']\n",
        "            category = d_paper['category']\n",
        "            html_content += f\"<h1><a href='{url}'>{title}</a></h1>\\n\"\n",
        "            html_content += f\"<p>{summary}</p>\\n<hr>\\n\"\n",
        "            html_content += f\"<p>Examples: {examples}</p>\\n<hr>\\n\"\n",
        "            html_content += f\"<p>Category: {category}</p>\\n<hr>\\n\"\n",
        "\n",
        "html_content += \"\"\"</body>\n",
        "</html>\"\"\"\n",
        "\n",
        "# Write HTML to file\n",
        "with open('paper_summaries.html', 'w') as f:\n",
        "    f.write(html_content)\n"
      ],
      "metadata": {
        "id": "X-tXZXNKAZNB",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "77060d83-a3fc-453d-b252-dc1a050e2c5e"
      },
      "execution_count": 33,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "time: 22.3 ms (started: 2025-02-22 16:36:05 +00:00)\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "## Save data to GDrive\n",
        "\n",
        "Save zipped data, cp it to Drive timestamped with day papers refer to."
      ],
      "metadata": {
        "id": "k2kNMCpvpcAM"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "# zip responses folder and all JSON and HTML files\n",
        "!zip -r data.zip responses *.json *.html"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "TfvvtmTTh6FO",
        "outputId": "6efdf3aa-a396-49e2-e953-bdac8c6baf0d"
      },
      "execution_count": 36,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "updating: responses/ (stored 0%)\n",
            "updating: responses/2502.14572.json (deflated 43%)\n",
            "updating: responses/2502.14361.json (deflated 43%)\n",
            "updating: responses/2502.14837.json (deflated 37%)\n",
            "updating: responses/2502.14048.json (deflated 49%)\n",
            "updating: responses/2502.14302.json (deflated 52%)\n",
            "updating: responses/2502.13969.json (deflated 44%)\n",
            "updating: responses/2502.14086.json (deflated 45%)\n",
            "updating: responses/2502.14560.json (deflated 50%)\n",
            "updating: responses/2502.14001.json (deflated 48%)\n",
            "updating: responses/2502.14400.json (deflated 46%)\n",
            "updating: responses/2502.14280.json (deflated 44%)\n",
            "updating: responses/2502.14499.json (deflated 45%)\n",
            "updating: responses/2502.14768.json (deflated 45%)\n",
            "updating: responses/2502.14457.json (deflated 45%)\n",
            "updating: responses/2502.14862.json (deflated 45%)\n",
            "updating: responses/2502.14264.json (deflated 47%)\n",
            "updating: responses/2502.14276.json (deflated 43%)\n",
            "updating: responses/2502.14281.json (deflated 48%)\n",
            "updating: responses/2502.13983.json (deflated 46%)\n",
            "updating: responses/2502.14486.json (deflated 50%)\n",
            "updating: responses/2502.14204.json (deflated 41%)\n",
            "updating: responses/2502.14272.json (deflated 42%)\n",
            "updating: responses/2502.14791.json (deflated 46%)\n",
            "updating: responses/2502.14297.json (deflated 46%)\n",
            "updating: responses/2502.14767.json (deflated 42%)\n",
            "updating: responses/2502.14380.json (deflated 42%)\n",
            "updating: responses/2502.14714.json (deflated 47%)\n",
            "updating: responses/2502.14102.json (deflated 51%)\n",
            "updating: responses/2502.14799.json (deflated 47%)\n",
            "updating: responses/2502.14074.json (deflated 48%)\n",
            "updating: responses/2502.14708.json (deflated 50%)\n",
            "updating: responses/2502.14765.json (deflated 41%)\n",
            "updating: responses/2502.14219.json (deflated 46%)\n",
            "updating: responses/2502.14174.json (deflated 45%)\n",
            "updating: responses/2502.14815.json (deflated 46%)\n",
            "updating: responses/2502.14802.json (deflated 43%)\n",
            "updating: responses/2502.14445.json (deflated 46%)\n",
            "updating: responses/2502.14011.json (deflated 47%)\n",
            "updating: responses/2502.14008.json (deflated 47%)\n",
            "updating: responses/2502.14316.json (deflated 43%)\n",
            "updating: responses/2502.14558.json (deflated 48%)\n",
            "updating: responses/2502.14504.json (deflated 42%)\n",
            "updating: responses/2502.14706.json (deflated 47%)\n",
            "updating: responses/2502.14727.json (deflated 48%)\n",
            "updating: responses/2502.14619.json (deflated 46%)\n",
            "updating: responses/2502.14114.json (deflated 43%)\n",
            "updating: responses/2502.14456.json (deflated 49%)\n",
            "updating: responses/2502.14235.json (deflated 43%)\n",
            "updating: responses/2502.14491.json (deflated 43%)\n",
            "updating: responses/2502.14780.json (deflated 44%)\n",
            "updating: responses/2502.14068.json (deflated 44%)\n",
            "updating: responses/2502.14698.json (deflated 43%)\n",
            "updating: responses/2502.14820.json (deflated 44%)\n",
            "updating: responses/2502.14365.json (deflated 48%)\n",
            "updating: responses/2502.14382.json (deflated 36%)\n",
            "updating: responses/2502.14176.json (deflated 54%)\n",
            "updating: responses/2502.13998.json (deflated 43%)\n",
            "updating: responses/2502.14149.json (deflated 42%)\n",
            "updating: responses/2502.14215.json (deflated 45%)\n",
            "updating: responses/2502.14345.json (deflated 44%)\n",
            "updating: responses/2502.14416.json (deflated 41%)\n",
            "updating: responses/2502.14155.json (deflated 41%)\n",
            "updating: responses/2502.14121.json (deflated 49%)\n",
            "updating: responses/2502.14227.json (deflated 45%)\n",
            "updating: responses/2502.14064.json (deflated 48%)\n",
            "updating: responses/2502.14553.json (deflated 46%)\n",
            "updating: responses/2502.14023.json (deflated 43%)\n",
            "updating: responses/2502.14760.json (deflated 42%)\n",
            "updating: responses/2502.14759.json (deflated 44%)\n",
            "updating: responses/2502.14268.json (deflated 55%)\n",
            "updating: responses/2502.14455.json (deflated 44%)\n",
            "updating: responses/2502.14202.json (deflated 44%)\n",
            "updating: responses/2502.14043.json (deflated 43%)\n",
            "updating: responses/2502.14866.json (deflated 42%)\n",
            "updating: responses/2502.14254.json (deflated 32%)\n",
            "updating: responses/2502.14704.json (deflated 51%)\n",
            "updating: responses/2502.14525.json (deflated 46%)\n",
            "updating: responses/2502.14838.json (deflated 46%)\n",
            "updating: responses/2502.14010.json (deflated 45%)\n",
            "updating: responses/2502.14753.json (deflated 46%)\n",
            "updating: responses/2502.14045.json (deflated 45%)\n",
            "updating: responses/2502.14583.json (deflated 54%)\n",
            "updating: responses/2502.14546.json (deflated 42%)\n",
            "updating: responses/2502.13979.json (deflated 44%)\n",
            "updating: responses/2502.14442.json (deflated 51%)\n",
            "updating: responses/2502.14255.json (deflated 44%)\n",
            "updating: responses/2502.14830.json (deflated 47%)\n",
            "updating: responses/2502.14827.json (deflated 41%)\n",
            "updating: responses/2502.14050.json (deflated 52%)\n",
            "updating: responses/2502.14529.json (deflated 41%)\n",
            "updating: responses/2502.14070.json (deflated 46%)\n",
            "updating: responses/2502.14013.json (deflated 43%)\n",
            "updating: responses/2502.14735.json (deflated 47%)\n",
            "updating: responses/2502.14366.json (deflated 45%)\n",
            "updating: responses/2502.14807.json (deflated 46%)\n",
            "updating: responses/2502.14424.json (deflated 42%)\n",
            "updating: responses/2502.14047.json (deflated 46%)\n",
            "updating: responses/2502.14132.json (deflated 46%)\n",
            "updating: responses/2502.14372.json (deflated 52%)\n",
            "updating: responses/2502.14019.json (deflated 45%)\n",
            "updating: responses/2502.14333.json (deflated 44%)\n",
            "updating: responses/2502.14000.json (deflated 47%)\n",
            "updating: responses/2502.14627.json (deflated 47%)\n",
            "updating: responses/2502.14645.json (deflated 45%)\n",
            "updating: responses/2502.14218.json (deflated 42%)\n",
            "updating: responses/2502.14637.json (deflated 44%)\n",
            "updating: responses/2502.14458.json (deflated 44%)\n",
            "updating: responses/2502.14293.json (deflated 44%)\n",
            "updating: responses/2502.14205.json (deflated 40%)\n",
            "updating: responses/2502.14462.json (deflated 51%)\n",
            "updating: responses/2502.14671.json (deflated 48%)\n",
            "updating: responses/2502.14003.json (deflated 47%)\n",
            "updating: responses/2502.14200.json (deflated 46%)\n",
            "updating: responses/2502.14831.json (deflated 49%)\n",
            "updating: responses/2502.14061.json (deflated 45%)\n",
            "updating: responses/2502.14160.json (deflated 46%)\n",
            "updating: responses/2502.14856.json (deflated 44%)\n",
            "updating: responses/2502.14113.json (deflated 47%)\n",
            "updating: responses/2502.14677.json (deflated 43%)\n",
            "updating: responses/2502.14334.json (deflated 50%)\n",
            "updating: responses/2502.14864.json (deflated 49%)\n",
            "updating: responses/2502.14318.json (deflated 44%)\n",
            "updating: responses/2502.14785.json (deflated 45%)\n",
            "updating: responses/2502.14563.json (deflated 44%)\n",
            "updating: responses/2502.14183.json (deflated 42%)\n",
            "updating: responses/2502.14080.json (deflated 44%)\n",
            "updating: responses/2502.14301.json (deflated 45%)\n",
            "updating: responses/2502.14273.json (deflated 47%)\n",
            "updating: responses/2502.14260.json (deflated 48%)\n",
            "updating: responses/2502.14676.json (deflated 56%)\n",
            "updating: responses/2502.14743.json (deflated 44%)\n",
            "updating: responses/2502.14197.json (deflated 48%)\n",
            "updating: responses/2502.14258.json (deflated 45%)\n",
            "updating: responses/2502.14777.json (deflated 47%)\n",
            "updating: responses/2502.14469.json (deflated 42%)\n",
            "updating: responses/2502.14786.json (deflated 46%)\n",
            "updating: responses/2502.14131.json (deflated 43%)\n",
            "updating: responses/2502.14834.json (deflated 44%)\n",
            "updating: responses/2502.14778.json (deflated 46%)\n",
            "updating: responses/2502.14487.json (deflated 45%)\n",
            "updating: responses/2502.14222.json (deflated 44%)\n",
            "updating: responses/2502.14037.json (deflated 48%)\n",
            "updating: responses/2502.14740.json (deflated 41%)\n",
            "updating: responses/2502.14191.json (deflated 42%)\n",
            "updating: responses/2502.14581.json (deflated 55%)\n",
            "updating: responses/2502.14681.json (deflated 49%)\n",
            "updating: responses/2502.13991.json (deflated 50%)\n",
            "updating: responses/2502.14620.json (deflated 47%)\n",
            "updating: responses/2502.13972.json (deflated 42%)\n",
            "updating: responses/2502.14143.json (deflated 44%)\n",
            "updating: responses/2502.14247.json (deflated 51%)\n",
            "updating: responses/2502.13994.json (deflated 45%)\n",
            "updating: responses/2502.14788.json (deflated 41%)\n",
            "updating: responses/2502.14724.json (deflated 45%)\n",
            "updating: latency.json (deflated 68%)\n",
            "updating: usage.json (deflated 92%)\n",
            "  adding: paper_metadata.json (deflated 90%)\n",
            "  adding: paper_summaries.html (deflated 68%)\n",
            "time: 106 ms (started: 2025-02-22 16:40:22 +00:00)\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "# needs to mount the Drive first\n",
        "drive.mount('/content/drive')\n",
        "\n",
        "day_object = datetime.strptime(day, \"%a, %d %b %Y \")\n",
        "formatted_day = day_object.strftime(\"%Y-%m-%d\")\n",
        "\n",
        "# cp and rename\n",
        "!cp *.zip /content/drive/MyDrive/\n",
        "!mv /content/drive/MyDrive/data.zip /content/drive/MyDrive/{formatted_day}_data_papers.zip"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "UDZegyiQV8j2",
        "outputId": "d4201fe7-6ee2-4bc2-bae5-124539ceec36"
      },
      "execution_count": 37,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Drive already mounted at /content/drive; to attempt to forcibly remount, call drive.mount(\"/content/drive\", force_remount=True).\n",
            "time: 1.6 s (started: 2025-02-22 16:40:29 +00:00)\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "# you could also send that summary HTML via email if you want\n",
        "# or publish it somewhere\n",
        "# I may just keep it as is for now while I test this for a few days\n",
        "# currently testing how categories get created\n",
        "\n",
        "# TODOs\n",
        "# org/univ it came from - maybe if acedmic or not too\n",
        "# these^ to be shown in html and put together by theme, with TOC at top\n",
        "# check that zipped file is actually permanend in drive (not sure)"
      ],
      "metadata": {
        "id": "inT2pAbUA8AT",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "3acab80a-5734-4377-fa1f-77b6990e2262"
      },
      "execution_count": 20,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "time: 450 µs (started: 2025-02-22 16:14:41 +00:00)\n"
          ]
        }
      ]
    }
  ]
}