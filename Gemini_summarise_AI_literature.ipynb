{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "provenance": [],
      "authorship_tag": "ABX9TyNlDC4IVqGO7UTT466Ji64w",
      "include_colab_link": true
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "language_info": {
      "name": "python"
    }
  },
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "view-in-github",
        "colab_type": "text"
      },
      "source": [
        "<a href=\"https://colab.research.google.com/github/martinapugliese/summarise-sci-literature/blob/main/Gemini_summarise_AI_literature.ipynb\" target=\"_parent\"><img src=\"https://colab.research.google.com/assets/colab-badge.svg\" alt=\"Open In Colab\"/></a>"
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "# this is to get time execution on each cell\n",
        "!pip install ipython-autotime\n",
        "\n",
        "%load_ext autotime"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "6TV5IJ7fZ3uL",
        "outputId": "ec8075a8-84f4-4f58-f7f3-fef9611810c2"
      },
      "execution_count": 36,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Requirement already satisfied: ipython-autotime in /usr/local/lib/python3.11/dist-packages (0.3.2)\n",
            "Requirement already satisfied: ipython in /usr/local/lib/python3.11/dist-packages (from ipython-autotime) (7.34.0)\n",
            "Requirement already satisfied: setuptools>=18.5 in /usr/local/lib/python3.11/dist-packages (from ipython->ipython-autotime) (75.1.0)\n",
            "Requirement already satisfied: jedi>=0.16 in /usr/local/lib/python3.11/dist-packages (from ipython->ipython-autotime) (0.19.2)\n",
            "Requirement already satisfied: decorator in /usr/local/lib/python3.11/dist-packages (from ipython->ipython-autotime) (4.4.2)\n",
            "Requirement already satisfied: pickleshare in /usr/local/lib/python3.11/dist-packages (from ipython->ipython-autotime) (0.7.5)\n",
            "Requirement already satisfied: traitlets>=4.2 in /usr/local/lib/python3.11/dist-packages (from ipython->ipython-autotime) (5.7.1)\n",
            "Requirement already satisfied: prompt-toolkit!=3.0.0,!=3.0.1,<3.1.0,>=2.0.0 in /usr/local/lib/python3.11/dist-packages (from ipython->ipython-autotime) (3.0.50)\n",
            "Requirement already satisfied: pygments in /usr/local/lib/python3.11/dist-packages (from ipython->ipython-autotime) (2.18.0)\n",
            "Requirement already satisfied: backcall in /usr/local/lib/python3.11/dist-packages (from ipython->ipython-autotime) (0.2.0)\n",
            "Requirement already satisfied: matplotlib-inline in /usr/local/lib/python3.11/dist-packages (from ipython->ipython-autotime) (0.1.7)\n",
            "Requirement already satisfied: pexpect>4.3 in /usr/local/lib/python3.11/dist-packages (from ipython->ipython-autotime) (4.9.0)\n",
            "Requirement already satisfied: parso<0.9.0,>=0.8.4 in /usr/local/lib/python3.11/dist-packages (from jedi>=0.16->ipython->ipython-autotime) (0.8.4)\n",
            "Requirement already satisfied: ptyprocess>=0.5 in /usr/local/lib/python3.11/dist-packages (from pexpect>4.3->ipython->ipython-autotime) (0.7.0)\n",
            "Requirement already satisfied: wcwidth in /usr/local/lib/python3.11/dist-packages (from prompt-toolkit!=3.0.0,!=3.0.1,<3.1.0,>=2.0.0->ipython->ipython-autotime) (0.2.13)\n",
            "The autotime extension is already loaded. To reload it, use:\n",
            "  %reload_ext autotime\n",
            "time: 3.93 s (started: 2025-02-15 11:39:26 +00:00)\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "from google.colab import userdata\n",
        "\n",
        "from google import genai\n",
        "from google.genai import Client, types\n",
        "\n",
        "import requests\n",
        "import urllib.request as urllib_req\n",
        "\n",
        "from bs4 import BeautifulSoup\n",
        "\n",
        "from datetime import date, datetime\n",
        "\n",
        "import re\n",
        "\n",
        "import os\n",
        "import json\n",
        "\n",
        "import numpy as np"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "MjqfEPBGNaoE",
        "outputId": "35f9a3c8-27e7-4ba8-b822-35a7853da27b"
      },
      "execution_count": 68,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "time: 694 µs (started: 2025-02-15 12:39:00 +00:00)\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "## Configs"
      ],
      "metadata": {
        "id": "PYFL0-uMJqOY"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "client = genai.Client(api_key=userdata.get('GEMINI_API_KEY'))"
      ],
      "metadata": {
        "id": "rsM-SO6JNqud"
      },
      "execution_count": 2,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# configure which Gemini to run\n",
        "model = \"gemini-2.0-flash-lite-preview-02-05\"\n",
        "model = \"gemini-2.0-flash\""
      ],
      "metadata": {
        "id": "HFu1maz4PK_Y"
      },
      "execution_count": 3,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "## Scrape ArXiv page for latest day's AI papers\n",
        "\n",
        "Get the paper links and IDs. Use the most recent days of publications available."
      ],
      "metadata": {
        "id": "AwAzV6WeJc-4"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "webpage = \"https://arxiv.org/list/cs.AI/recent?skip=0&show=2000\"  # this is the URL for all, so no need to paginate\n",
        "\n",
        "r = requests.get(webpage)\n",
        "r.status_code  # you want a 200 here"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "collapsed": true,
        "id": "aUUr_6uZTz9A",
        "outputId": "57a310f7-3817-431d-f58c-3189fdc2984d"
      },
      "execution_count": 9,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "200"
            ]
          },
          "metadata": {},
          "execution_count": 9
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "# initialise the parser\n",
        "soup = BeautifulSoup(r.content, \"html.parser\")"
      ],
      "metadata": {
        "id": "qM02iz80NXLZ"
      },
      "execution_count": 10,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# pick the phrasing of the most recent day\n",
        "latest_day_str = soup.find_all(\"h3\")[0].text\n",
        "\n",
        "# match what's this latest day\n",
        "day = latest_day_str.split('(')[0]\n",
        "\n",
        "# and the total number of entries for that day\n",
        "match = re.search(r'of \\d+ entries', latest_day_str)\n",
        "if match:\n",
        "    n_entries = int(match.group().split(' ')[1])\n",
        "    print(day, ' - ', n_entries, 'papers')\n",
        "else:\n",
        "    print(\"Failed to isolate latest day's info\")"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "xhte_voMMnxT",
        "outputId": "dbec2c2a-e412-42a0-bbcb-cfbdd96415e2"
      },
      "execution_count": 11,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Fri, 14 Feb 2025   -  159 papers\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "# now find the URLs to these papers for the latest day only (up to n_entries as per above)\n",
        "paper_links = soup.find_all(\"a\", {\"title\": \"Download PDF\"})[:n_entries]\n",
        "\n",
        "# Extract the paper IDs and links\n",
        "paper_ids, paper_urls = [], []\n",
        "for link in paper_links:\n",
        "    paper_url = \"https://arxiv.org\" + link[\"href\"]\n",
        "    paper_id = link[\"href\"].split(\"/\")[-1].split(\"v\")[0]  # Extract the ID\n",
        "\n",
        "    paper_ids.append(paper_id)\n",
        "    paper_urls.append(paper_url)\n",
        "\n",
        "# # Print the IDs and links (or process them as needed)\n",
        "# for i in range(len(paper_ids)):\n",
        "#     print(f\"Paper ID: {paper_ids[i]}, URL: {paper_urls[i]}\")"
      ],
      "metadata": {
        "id": "Fp1ngoJ-YYbJ"
      },
      "execution_count": 22,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# separately, find all titles (this is due to how the DOM is structured)\n",
        "# they'll appear in the same order so order counts\n",
        "paper_title_divs = soup.find_all(\"div\", {\"class\": \"list-title mathjax\"})[:n_entries]\n",
        "\n",
        "paper_titles = []\n",
        "for title_div in paper_title_divs:\n",
        "    paper_titles.append(title_div.contents[1].split('\\n')[1].lstrip())"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "collapsed": true,
        "id": "A7GBjw9ECsoq",
        "outputId": "aa9aa3b6-fd1a-46d6-c9a6-37d95ea7a27f"
      },
      "execution_count": 103,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "time: 39.8 ms (started: 2025-02-15 14:44:08 +00:00)\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "len(paper_urls), len(paper_ids), len(paper_links), len(paper_titles)"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "Zi8o9t3lKwml",
        "outputId": "d8d3eb1f-9e36-460a-a25a-b990822c2181"
      },
      "execution_count": 104,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "(159, 159, 159, 159)"
            ]
          },
          "metadata": {},
          "execution_count": 104
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "time: 3.91 ms (started: 2025-02-15 14:44:23 +00:00)\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "# create json linking ID, title and URL\n",
        "paper_metadata = {paper_ids[i]: {'title': paper_titles[i], 'url': paper_urls[i]} for i in range(len(paper_ids))}\n",
        "json.dump(paper_metadata, open('paper_metadata.json', 'w'))"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "LpzPSOkY_0GH",
        "outputId": "fb804609-51ad-4ae1-b94d-39b5ffc3049b"
      },
      "execution_count": 121,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "time: 4.57 ms (started: 2025-02-15 14:55:42 +00:00)\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "## Download all papers locally"
      ],
      "metadata": {
        "id": "NHv-Foa5Ko0V"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "os.mkdir('pdfs')\n",
        "\n",
        "i = 0\n",
        "for id_, url_ in zip(paper_ids, paper_urls):\n",
        "    _ = urllib_req.urlretrieve(url_, f\"pdfs/{id_}.pdf\")\n",
        "\n",
        "    i += 1\n",
        "    if i % 10 == 0:\n",
        "        print(f\"Downloaded {i} papers\")"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "GsZItTXDZEKu",
        "outputId": "be88f2bf-68b7-413e-db20-634f44236dc3"
      },
      "execution_count": 47,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Downloaded 10 papers\n",
            "Downloaded 20 papers\n",
            "Downloaded 30 papers\n",
            "Downloaded 40 papers\n",
            "Downloaded 50 papers\n",
            "Downloaded 60 papers\n",
            "Downloaded 70 papers\n",
            "Downloaded 80 papers\n",
            "Downloaded 90 papers\n",
            "Downloaded 100 papers\n",
            "Downloaded 110 papers\n",
            "Downloaded 120 papers\n",
            "Downloaded 130 papers\n",
            "Downloaded 140 papers\n",
            "Downloaded 150 papers\n",
            "time: 22.2 s (started: 2025-02-15 12:07:20 +00:00)\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "len(os.listdir('pdfs'))  # just to check count"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "kviwBfwughb1",
        "outputId": "5cc93d79-85dd-4593-fa68-dafe5e95dd55"
      },
      "execution_count": 51,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "159"
            ]
          },
          "metadata": {},
          "execution_count": 51
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "time: 3.52 ms (started: 2025-02-15 12:08:13 +00:00)\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "## Make Gemini summarise each paper"
      ],
      "metadata": {
        "id": "9TD9hhq-aoM1"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "# prompt\n",
        "sys_instruct = \"\"\"\n",
        "                You are an experienced reader of academic literature and\n",
        "                an expert in distilling important findings in a way that is understandable and clear.\n",
        "               \"\"\"\n",
        "\n",
        "prompt = \"\"\"This is a paper on AI.\n",
        "            Summarise its results in 3 lines, avoiding obscure jargon and going to the point.\n",
        "            If there are valuable examples that aid understanding, report them in a nutshell.\n",
        "            \"\"\""
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "1Qu4OSOYgfC8",
        "outputId": "10d64c6f-9fe7-4f0d-a2c8-08b51e5dd8c1"
      },
      "execution_count": 52,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "time: 359 µs (started: 2025-02-15 12:08:15 +00:00)\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "# create a dir for model responses (text)\n",
        "os.mkdir('responses')"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "J9--OwUrgu_m",
        "outputId": "34f8b1c9-b02b-4447-bbd4-850c854acabe"
      },
      "execution_count": 111,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "time: 733 µs (started: 2025-02-15 14:50:28 +00:00)\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "# create some dicts for metadata\n",
        "d_usage, d_latency = {}, {}"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "d-6V3-QyiMdi",
        "outputId": "4d61f99c-9294-4e82-add3-d46f58a542f0"
      },
      "execution_count": 61,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "time: 546 µs (started: 2025-02-15 12:15:30 +00:00)\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "i = 0\n",
        "for filename in os.listdir('pdfs')[:3]:\n",
        "\n",
        "    print(filename, i)\n",
        "\n",
        "    # this passes the file as is to Gemini, no need to read its text content first\n",
        "    file_ = client.files.upload(file=f'pdfs/{filename}')\n",
        "    start_time = datetime.now()\n",
        "    response = client.models.generate_content(\n",
        "        model=model,\n",
        "        config=types.GenerateContentConfig(system_instruction=sys_instruct),\n",
        "        contents=[prompt, file_])\n",
        "    end_time = datetime.now()\n",
        "\n",
        "    id_ = filename.split('.pdf')[0]\n",
        "    d_usage[id_] = {\n",
        "        'prompt_token_count': response.usage_metadata.prompt_token_count,\n",
        "        'candidates_token_count': response.usage_metadata.candidates_token_count,\n",
        "        'cached_content_token_count': response.usage_metadata.cached_content_token_count}\n",
        "    d_latency[id_] = (end_time - start_time).total_seconds()\n",
        "\n",
        "    # create file of text response\n",
        "    with open(f'responses/{id_}.txt', 'w') as f:\n",
        "        f.write(response.text)\n",
        "\n",
        "    # also dump usage and latency at each execution\n",
        "    json.dump(d_usage, open(f'usage.json', 'w'))\n",
        "    json.dump(d_latency, open(f'latency.json', 'w'))\n",
        "\n",
        "    i += 1"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "fJtFYt0tZHe9",
        "outputId": "6a84d81a-4018-4391-872a-a1eaeafa095f"
      },
      "execution_count": 115,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "2502.08689.pdf 0\n",
            "2502.08821.pdf 1\n",
            "2502.09051.pdf 2\n",
            "time: 17.1 s (started: 2025-02-15 14:51:11 +00:00)\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "## Run some stats"
      ],
      "metadata": {
        "id": "wtUaxd2Qjhup"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "# num papers summarised\n",
        "print('Summaries for ', day)\n",
        "print('Num papers published: ', n_entries)\n",
        "print('Num papers summarised: ', len(os.listdir('responses')))\n",
        "print('Median input/output tokens',\n",
        "      np.percentile([d_usage[k]['prompt_token_count'] for k in d_usage.keys()], 50),\n",
        "      np.percentile([d_usage[k]['candidates_token_count'] for k in d_usage.keys()], 50))\n",
        "print('Median/P90 latency per paper: ',\n",
        "      np.percentile([d_latency[k] for k in d_usage.keys()], 50),\n",
        "      np.percentile([d_latency[k] for k in d_usage.keys()], 90))"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "BZmHoOp4jjAn",
        "outputId": "6b251c73-7e3e-4abb-9a28-769e0d55d8f0"
      },
      "execution_count": 117,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Summaries for  Fri, 14 Feb 2025 \n",
            "Num papers published:  159\n",
            "Num papers summarised:  159\n",
            "Median input/output tokens 3691.0 130.0\n",
            "Median/P90 latency per paper:  4.945586 8.389815600000006\n",
            "time: 10.6 ms (started: 2025-02-15 14:52:24 +00:00)\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "# zip all responses\n",
        "!zip -r responses.zip responses"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "collapsed": true,
        "id": "aNJnwAIMoBvR",
        "outputId": "7df776d1-e4cb-43f9-a60a-748144463a16"
      },
      "execution_count": 75,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "  adding: responses/ (stored 0%)\n",
            "  adding: responses/2502.09233.pdf.txt (deflated 41%)\n",
            "  adding: responses/2502.09218.pdf.txt (deflated 41%)\n",
            "  adding: responses/2502.08652.pdf.txt (deflated 41%)\n",
            "  adding: responses/2502.09387.pdf.txt (deflated 45%)\n",
            "  adding: responses/2502.08828.pdf.txt (deflated 43%)\n",
            "  adding: responses/2502.09051.pdf.txt (deflated 39%)\n",
            "  adding: responses/2502.09460.pdf.txt (deflated 43%)\n",
            "  adding: responses/2502.09211.pdf.txt (deflated 48%)\n",
            "  adding: responses/2502.08920.pdf.txt (deflated 44%)\n",
            "  adding: responses/2502.09307.pdf.txt (deflated 43%)\n",
            "  adding: responses/2502.09183.pdf.txt (deflated 46%)\n",
            "  adding: responses/2502.09604.pdf.txt (deflated 46%)\n",
            "  adding: responses/2502.09365.pdf.txt (deflated 42%)\n",
            "  adding: responses/2502.08884.pdf.txt (deflated 45%)\n",
            "  adding: responses/2502.09601.pdf.txt (deflated 43%)\n",
            "  adding: responses/2502.09038.pdf.txt (deflated 44%)\n",
            "  adding: responses/2502.08916.pdf.txt (deflated 43%)\n",
            "  adding: responses/2502.09247.pdf.txt (deflated 49%)\n",
            "  adding: responses/2502.08661.pdf.txt (deflated 45%)\n",
            "  adding: responses/2502.09053.pdf.txt (deflated 45%)\n",
            "  adding: responses/2502.08864.pdf.txt (deflated 48%)\n",
            "  adding: responses/2502.08869.pdf.txt (deflated 45%)\n",
            "  adding: responses/2502.09622.pdf.txt (deflated 44%)\n",
            "  adding: responses/2502.09567.pdf.txt (deflated 41%)\n",
            "  adding: responses/2502.09205.pdf.txt (deflated 45%)\n",
            "  adding: responses/2502.09082.pdf.txt (deflated 41%)\n",
            "  adding: responses/2502.08754.pdf.txt (deflated 40%)\n",
            "  adding: responses/2502.09257.pdf.txt (deflated 47%)\n",
            "  adding: responses/2502.08792.pdf.txt (deflated 47%)\n",
            "  adding: responses/2502.09271.pdf.txt (deflated 45%)\n",
            "  adding: responses/2502.09443.pdf.txt (deflated 46%)\n",
            "  adding: responses/2502.09284.pdf.txt (deflated 44%)\n",
            "  adding: responses/2502.07352.pdf.txt (deflated 46%)\n",
            "  adding: responses/2502.09220.pdf.txt (deflated 50%)\n",
            "  adding: responses/2502.08886.pdf.txt (deflated 42%)\n",
            "  adding: responses/2502.09232.pdf.txt (deflated 47%)\n",
            "  adding: responses/2502.08858.pdf.txt (deflated 41%)\n",
            "  adding: responses/2502.09046.pdf.txt (deflated 42%)\n",
            "  adding: responses/2502.09216.pdf.txt (deflated 43%)\n",
            "  adding: responses/2502.08908.pdf.txt (deflated 45%)\n",
            "  adding: responses/2502.08896.pdf.txt (deflated 44%)\n",
            "  adding: responses/2502.08820.pdf.txt (deflated 39%)\n",
            "  adding: responses/2502.09054.pdf.txt (deflated 41%)\n",
            "  adding: responses/2502.09020.pdf.txt (deflated 38%)\n",
            "  adding: responses/2502.08995.pdf.txt (deflated 41%)\n",
            "  adding: responses/2502.09055.pdf.txt (deflated 47%)\n",
            "  adding: responses/2502.08784.pdf.txt (deflated 46%)\n",
            "  adding: responses/2502.08989.pdf.txt (deflated 44%)\n",
            "  adding: responses/2502.09503.pdf.txt (deflated 45%)\n",
            "  adding: responses/2502.08923.pdf.txt (deflated 45%)\n",
            "  adding: responses/2502.09484.pdf.txt (deflated 41%)\n",
            "  adding: responses/2502.09104.pdf.txt (deflated 40%)\n",
            "  adding: responses/2502.08972.pdf.txt (deflated 44%)\n",
            "  adding: responses/2502.09606.pdf.txt (deflated 42%)\n",
            "  adding: responses/2502.09039.pdf.txt (deflated 45%)\n",
            "  adding: responses/2502.08898.pdf.txt (deflated 49%)\n",
            "  adding: responses/2502.08774.pdf.txt (deflated 44%)\n",
            "  adding: responses/2502.08941.pdf.txt (deflated 42%)\n",
            "  adding: responses/2502.09173.pdf.txt (deflated 43%)\n",
            "  adding: responses/2502.08904.pdf.txt (deflated 42%)\n",
            "  adding: responses/2502.09022.pdf.txt (deflated 42%)\n",
            "  adding: responses/2502.09125.pdf.txt (deflated 41%)\n",
            "  adding: responses/2502.09219.pdf.txt (deflated 39%)\n",
            "  adding: responses/2502.08664.pdf.txt (deflated 46%)\n",
            "  adding: responses/2502.08756.pdf.txt (deflated 40%)\n",
            "  adding: responses/2502.08821.pdf.txt (deflated 41%)\n",
            "  adding: responses/2502.09379.pdf.txt (deflated 37%)\n",
            "  adding: responses/2502.09335.pdf.txt (deflated 42%)\n",
            "  adding: responses/2502.08969.pdf.txt (deflated 44%)\n",
            "  adding: responses/2502.09212.pdf.txt (deflated 47%)\n",
            "  adding: responses/2502.08673.pdf.txt (deflated 32%)\n",
            "  adding: responses/2502.08681.pdf.txt (deflated 42%)\n",
            "  adding: responses/2502.09056.pdf.txt (deflated 40%)\n",
            "  adding: responses/2502.08689.pdf.txt (deflated 45%)\n",
            "  adding: responses/2502.09511.pdf.txt (deflated 43%)\n",
            "  adding: responses/2502.08679.pdf.txt (deflated 44%)\n",
            "  adding: responses/2502.08690.pdf.txt (deflated 40%)\n",
            "  adding: responses/2502.09221.pdf.txt (deflated 46%)\n",
            "  adding: responses/2502.08686.pdf.txt (deflated 43%)\n",
            "  adding: responses/2502.09436.pdf.txt (deflated 40%)\n",
            "  adding: responses/2502.09230.pdf.txt (deflated 44%)\n",
            "  adding: responses/2502.09417.pdf.txt (deflated 44%)\n",
            "  adding: responses/2502.08684.pdf.txt (deflated 41%)\n",
            "  adding: responses/2502.09122.pdf.txt (deflated 48%)\n",
            "  adding: responses/2502.09596.pdf.txt (deflated 40%)\n",
            "  adding: responses/2502.08874.pdf.txt (deflated 46%)\n",
            "  adding: responses/2502.08658.pdf.txt (deflated 44%)\n",
            "  adding: responses/2502.09560.pdf.txt (deflated 38%)\n",
            "  adding: responses/2502.08985.pdf.txt (deflated 40%)\n",
            "  adding: responses/2502.08662.pdf.txt (deflated 43%)\n",
            "  adding: responses/2502.08769.pdf.txt (deflated 33%)\n",
            "  adding: responses/2502.08691.pdf.txt (deflated 44%)\n",
            "  adding: responses/2502.09497.pdf.txt (deflated 40%)\n",
            "  adding: responses/2502.09228.pdf.txt (deflated 36%)\n",
            "  adding: responses/2502.08859.pdf.txt (deflated 37%)\n",
            "  adding: responses/2502.09432.pdf.txt (deflated 47%)\n",
            "  adding: responses/2502.08655.pdf.txt (deflated 41%)\n",
            "  adding: responses/2502.08903.pdf.txt (deflated 41%)\n",
            "  adding: responses/2502.09175.pdf.txt (deflated 38%)\n",
            "  adding: responses/2502.08909.pdf.txt (deflated 40%)\n",
            "  adding: responses/2502.08946.pdf.txt (deflated 44%)\n",
            "  adding: responses/2502.09305.pdf.txt (deflated 48%)\n",
            "  adding: responses/2502.08666.pdf.txt (deflated 51%)\n",
            "  adding: responses/2502.06772.pdf.txt (deflated 45%)\n",
            "  adding: responses/2502.09100.pdf.txt (deflated 44%)\n",
            "  adding: responses/2502.08914.pdf.txt (deflated 40%)\n",
            "  adding: responses/2502.08943.pdf.txt (deflated 41%)\n",
            "  adding: responses/2502.09235.pdf.txt (deflated 45%)\n",
            "  adding: responses/2502.09226.pdf.txt (deflated 45%)\n",
            "  adding: responses/2502.09620.pdf.txt (deflated 40%)\n",
            "  adding: responses/2502.09378.pdf.txt (deflated 43%)\n",
            "  adding: responses/2502.08834.pdf.txt (deflated 42%)\n",
            "  adding: responses/2502.08663.pdf.txt (deflated 43%)\n",
            "  adding: responses/2502.09294.pdf.txt (deflated 47%)\n",
            "  adding: responses/2502.09423.pdf.txt (deflated 42%)\n",
            "  adding: responses/2502.09188.pdf.txt (deflated 45%)\n",
            "  adding: responses/2502.08826.pdf.txt (deflated 41%)\n",
            "  adding: responses/2502.09471.pdf.txt (deflated 44%)\n",
            "  adding: responses/2502.09018.pdf.txt (deflated 43%)\n",
            "  adding: responses/2502.08922.pdf.txt (deflated 44%)\n",
            "  adding: responses/2502.08924.pdf.txt (deflated 41%)\n",
            "  adding: responses/2502.09495.pdf.txt (deflated 43%)\n",
            "  adding: responses/2502.08680.pdf.txt (deflated 37%)\n",
            "  adding: responses/2502.08759.pdf.txt (deflated 41%)\n",
            "  adding: responses/2502.09390.pdf.txt (deflated 38%)\n",
            "  adding: responses/2502.09222.pdf.txt (deflated 45%)\n",
            "  adding: responses/2502.09215.pdf.txt (deflated 44%)\n",
            "  adding: responses/2502.09209.pdf.txt (deflated 42%)\n",
            "  adding: responses/2502.08682.pdf.txt (deflated 46%)\n",
            "  adding: responses/2502.09389.pdf.txt (deflated 45%)\n",
            "  adding: responses/2502.08685.pdf.txt (deflated 42%)\n",
            "  adding: responses/2502.09532.pdf.txt (deflated 43%)\n",
            "  adding: responses/2502.08942.pdf.txt (deflated 46%)\n",
            "  adding: responses/2502.09614.pdf.txt (deflated 42%)\n",
            "  adding: responses/2502.08696.pdf.txt (deflated 46%)\n",
            "  adding: responses/2502.09565.pdf.txt (deflated 41%)\n",
            "  adding: responses/2502.09242.pdf.txt (deflated 40%)\n",
            "  adding: responses/2502.09256.pdf.txt (deflated 40%)\n",
            "  adding: responses/2502.09003.pdf.txt (deflated 42%)\n",
            "  adding: responses/2502.09609.pdf.txt (deflated 42%)\n",
            "  adding: responses/2502.09204.pdf.txt (deflated 40%)\n",
            "  adding: responses/2502.09224.pdf.txt (deflated 46%)\n",
            "  adding: responses/2502.09369.pdf.txt (deflated 43%)\n",
            "  adding: responses/2502.08987.pdf.txt (deflated 43%)\n",
            "  adding: responses/2502.08657.pdf.txt (deflated 42%)\n",
            "  adding: responses/2502.08932.pdf.txt (deflated 46%)\n",
            "  adding: responses/2502.08958.pdf.txt (deflated 44%)\n",
            "  adding: responses/2502.09083.pdf.txt (deflated 41%)\n",
            "  adding: responses/2502.09050.pdf.txt (deflated 42%)\n",
            "  adding: responses/2502.08806.pdf.txt (deflated 43%)\n",
            "  adding: responses/2502.09206.pdf.txt (deflated 41%)\n",
            "  adding: responses/2502.08939.pdf.txt (deflated 43%)\n",
            "  adding: responses/2502.09341.pdf.txt (deflated 42%)\n",
            "  adding: responses/2502.09487.pdf.txt (deflated 39%)\n",
            "  adding: responses/2502.08767.pdf.txt (deflated 43%)\n",
            "  adding: responses/2502.08966.pdf.txt (deflated 42%)\n",
            "  adding: responses/2502.09621.pdf.txt (deflated 39%)\n",
            "  adding: responses/2502.09042.pdf.txt (deflated 44%)\n",
            "  adding: responses/2502.09254.pdf.txt (deflated 42%)\n",
            "time: 107 ms (started: 2025-02-15 12:41:30 +00:00)\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "## Create HTML page with all summaries"
      ],
      "metadata": {
        "id": "OofFXJAPAFNv"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "paper_urls[:3]\n",
        "paper_metadata = json.load(open('paper_metadata.json', 'r'))"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "txNRTYzLoh-D",
        "outputId": "2ee32560-0dec-4902-ac8c-23ac67c46920"
      },
      "execution_count": 80,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "['https://arxiv.org/pdf/2502.09601',\n",
              " 'https://arxiv.org/pdf/2502.09596',\n",
              " 'https://arxiv.org/pdf/2502.09565']"
            ]
          },
          "metadata": {},
          "execution_count": 80
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "time: 29.1 ms (started: 2025-02-15 14:27:14 +00:00)\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "# this part below was contributed by Gemini after a prompt!\n",
        "# prompt: Create HTML document listing all texts in folder response one after the other. Use the data in paper_metadata to create titles for each entry and an href for the link\n",
        "\n",
        "# Load paper metadata\n",
        "paper_metadata = json.load(open('paper_metadata.json', 'r'))\n",
        "\n",
        "# Create HTML content\n",
        "html_content = \"\"\"<!DOCTYPE html>\n",
        "<html>\n",
        "<head>\n",
        "<title>Paper Summaries</title>\n",
        "</head>\n",
        "<body>\n",
        "\"\"\"\n",
        "\n",
        "for filename in os.listdir('responses'):\n",
        "    paper_id = filename.split('.txt')[0]\n",
        "    if paper_id in paper_metadata:\n",
        "      title = paper_metadata[paper_id]['title']\n",
        "      url = paper_metadata[paper_id]['url']\n",
        "      with open(os.path.join('responses', filename), 'r') as f:\n",
        "          summary = f.read()\n",
        "          html_content += f\"<h1><a href='{url}'>{title}</a></h1>\\n\"\n",
        "          html_content += f\"<p>{summary}</p>\\n<hr>\\n\"\n",
        "\n",
        "html_content += \"\"\"</body>\n",
        "</html>\"\"\"\n",
        "\n",
        "# Write HTML to file\n",
        "with open('paper_summaries.html', 'w') as f:\n",
        "    f.write(html_content)\n"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "X-tXZXNKAZNB",
        "outputId": "08653515-17ac-46f2-f0ee-2b398bfaad24"
      },
      "execution_count": 122,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "time: 12.6 ms (started: 2025-02-15 14:56:22 +00:00)\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "# now you could send that summary HTML via email if you want\n",
        "# or publish it somewhere\n",
        "# I may just keep it as is for now while I test this for a few days\n",
        "\n",
        "# the whole job could be made"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "inT2pAbUA8AT",
        "outputId": "996aaa40-6f09-4771-965c-df8dc5f9ebb7"
      },
      "execution_count": 123,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "time: 314 µs (started: 2025-02-15 14:57:50 +00:00)\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [],
      "metadata": {
        "id": "vGNrOgTsHaVt"
      },
      "execution_count": null,
      "outputs": []
    }
  ]
}